{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "model = fasttext.skipgram(\"zhwiki-latest-pages-articles.xml.bz2\", \"model\",dim = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "m = fasttext.load_model(\"wiki.zh.text.model\")\n",
    "# fasttext.load_model)\n",
    "print(m.similarity('queen',\"prince\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "d:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "d:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "d:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "d:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('百怪', 0.7097219228744507),\n",
       " ('bowonder', 0.6852757930755615),\n",
       " ('dneighborhood', 0.6847993731498718),\n",
       " ('辛卜生', 0.6843221187591553),\n",
       " ('ytsf', 0.6738196015357971),\n",
       " ('实纯量', 0.6672260761260986),\n",
       " ('解并', 0.667012095451355),\n",
       " ('普朗歇尔', 0.666632354259491),\n",
       " ('克氏符号', 0.6639362573623657),\n",
       " ('点光', 0.6620766520500183)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "wv_from_text = gensim.models.KeyedVectors.load_word2vec_format('wiki.zh.text.vector',binary=False)\n",
    "wv_from_text.init_sims(replace=True)  # 神奇，很省内存，可以运算most_similar\n",
    "#该操作是指model已经不再继续训练了，那么就锁定起来，让Model变为只读的，这样可以预载相似度矩阵，对于后面得相似查询非常有利。\n",
    "import numpy as np\n",
    "\n",
    "def compute_ngrams(word, min_n, max_n):\n",
    "    #BOW, EOW = ('<', '>')  # Used by FastText to attach to all words as prefix and suffix\n",
    "    extended_word =  word\n",
    "    ngrams = []\n",
    "    for ngram_length in range(min_n, min(len(extended_word), max_n) + 1):\n",
    "        for i in range(0, len(extended_word) - ngram_length + 1):\n",
    "            ngrams.append(extended_word[i:i + ngram_length])\n",
    "    return list(set(ngrams))\n",
    "\n",
    "\n",
    "def wordVec(word,wv_from_text,min_n = 1, max_n = 3):\n",
    "    '''\n",
    "    wordVec函数是计算未登录词的.\n",
    "    ngrams_single/ngrams_more,主要是为了当出现oov的情况下,最好先不考虑单字词向量\n",
    "    '''\n",
    "    # 确认词向量维度\n",
    "    word_size = wv_from_text.wv.syn0[0].shape[0]   \n",
    "    # 计算word的ngrams词组\n",
    "    ngrams = compute_ngrams(word,min_n = min_n, max_n = max_n)\n",
    "    # 如果在词典之中，直接返回词向量\n",
    "    if word in wv_from_text.wv.vocab.keys():\n",
    "        return wv_from_text[word]\n",
    "    else:  \n",
    "        # 不在词典的情况下\n",
    "        word_vec = np.zeros(word_size, dtype=np.float32)\n",
    "        ngrams_found = 0\n",
    "        ngrams_single = [ng for ng in ngrams if len(ng) == 1]\n",
    "        ngrams_more = [ng for ng in ngrams if len(ng) > 1]\n",
    "        # 先只接受2个单词长度以上的词向量\n",
    "        for ngram in ngrams_more:\n",
    "            if ngram in wv_from_text.wv.vocab.keys():\n",
    "                word_vec += wv_from_text[ngram]\n",
    "                ngrams_found += 1\n",
    "                #print(ngram)\n",
    "        # 如果，没有匹配到，那么最后是考虑单个词向量\n",
    "        if ngrams_found == 0:\n",
    "            for ngram in ngrams_single:\n",
    "                word_vec += wv_from_text[ngram]\n",
    "                ngrams_found += 1\n",
    "        if word_vec.any():\n",
    "            return word_vec / max(1, ngrams_found)\n",
    "        else:\n",
    "            raise KeyError('all ngrams for word %s absent from model' % word)\n",
    "    \n",
    "vec = wordVec('千奇百怪的词向量',wv_from_text,min_n = 1, max_n = 3)  # 词向量获取\n",
    "wv_from_text.most_similar(positive=[vec], topn=10)    # 相似词查找"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
